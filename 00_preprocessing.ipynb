{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Event-Logs\" data-toc-modified-id=\"Event-Logs-2\">Event Logs</a></span></li><li><span><a href=\"#Trace-Splitting\" data-toc-modified-id=\"Trace-Splitting-3\">Trace Splitting</a></span></li><li><span><a href=\"#Encoding-Techniques\" data-toc-modified-id=\"Encoding-Techniques-4\">Encoding Techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#PPObj\" data-toc-modified-id=\"PPObj-4.1\">PPObj</a></span></li><li><span><a href=\"#Categorization\" data-toc-modified-id=\"Categorization-4.2\">Categorization</a></span></li><li><span><a href=\"#Fill-Missing\" data-toc-modified-id=\"Fill-Missing-4.3\">Fill Missing</a></span></li><li><span><a href=\"#Z-score\" data-toc-modified-id=\"Z-score-4.4\">Z-score</a></span></li><li><span><a href=\"#Date-conversion\" data-toc-modified-id=\"Date-conversion-4.5\">Date conversion</a></span></li><li><span><a href=\"#MinMax-Scaling\" data-toc-modified-id=\"MinMax-Scaling-4.6\">MinMax Scaling</a></span></li><li><span><a href=\"#One-HoT-Encoding\" data-toc-modified-id=\"One-HoT-Encoding-4.7\">One HoT Encoding</a></span></li></ul></li><li><span><a href=\"#Sub-sequence-Generation\" data-toc-modified-id=\"Sub-sequence-Generation-5\">Sub-sequence Generation</a></span></li><li><span><a href=\"#Data-Loader\" data-toc-modified-id=\"Data-Loader-6\">Data Loader</a></span><ul class=\"toc-item\"><li><span><a href=\"#Integration-Samples\" data-toc-modified-id=\"Integration-Samples-6.1\">Integration Samples</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing\n",
    "===\n",
    "This notebook contains all relevant pre-processing. The implementation is based on the tabular notebooks in the fastai library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext memory_profiler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mppn.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All considered event logs are stored in `./event_logs`. The `EventLogs` class is a utility class to access each dataset. Logs can be loaded with the function `import_log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EventLogs:\n",
    "    Helpdesk=Path('./event_logs/Helpdesk.csv')\n",
    "    BPIC_12=Path('./event_logs/BPIC12.csv')\n",
    "    BPIC_12_W=Path('./event_logs/BPIC12_W.csv')\n",
    "    BPIC_12_Wcomplete=Path('./event_logs/BPIC12_Wc.csv')\n",
    "    BPIC_12_A=Path('./event_logs/BPIC12_A.csv')\n",
    "    BPIC_12_O=Path('./event_logs/BPIC12_O.csv')\n",
    "    BPIC_13_CP=Path('./event_logs/BPIC13_CP.csv')\n",
    "    BPIC_17_OFFER=Path('./event_logs/BPIC17_O.csv')\n",
    "    BPIC_20_RFP=Path('./event_logs/BPIC20_RFP.csv')\n",
    "    Mobis=Path('./event_logs/Mobis.csv')\n",
    "\n",
    "def import_log(ds): return pd.read_csv(ds,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170107\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>REG_DATE</th>\n",
       "      <th>AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2011-09-30 22:39:38.875000+00:00</td>\n",
       "      <td>W_Completeren aanvraag_SCHEDULE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 09:36:46.437000+00:00</td>\n",
       "      <td>W_Completeren aanvraag_START</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 09:45:11.554000+00:00</td>\n",
       "      <td>W_Nabellen offertes_SCHEDULE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 09:45:13.917000+00:00</td>\n",
       "      <td>W_Completeren aanvraag_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 10:15:41.290000+00:00</td>\n",
       "      <td>W_Nabellen offertes_START</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          event_id  resource                         timestamp  \\\n",
       "trace_id                                                         \n",
       "173688           0     112.0  2011-09-30 22:39:38.875000+00:00   \n",
       "173688           1       NaN  2011-10-01 09:36:46.437000+00:00   \n",
       "173688           2       NaN  2011-10-01 09:45:11.554000+00:00   \n",
       "173688           3       NaN  2011-10-01 09:45:13.917000+00:00   \n",
       "173688           4       NaN  2011-10-01 10:15:41.290000+00:00   \n",
       "\n",
       "                                 activity                          REG_DATE  \\\n",
       "trace_id                                                                      \n",
       "173688    W_Completeren aanvraag_SCHEDULE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688       W_Completeren aanvraag_START  2011-10-01 00:38:44.546000+02:00   \n",
       "173688       W_Nabellen offertes_SCHEDULE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688    W_Completeren aanvraag_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688          W_Nabellen offertes_START  2011-10-01 00:38:44.546000+02:00   \n",
       "\n",
       "          AMOUNT_REQ  \n",
       "trace_id              \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df=import_log(EventLogs.BPIC_12_W)\n",
    "print(len(event_df))\n",
    "event_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trace Splitting\n",
    "i.e. splitting in training, validation and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `split_traces` function is used to split an event_log into training, validation and test set. Furthermore, it removes traces that are longer than a specific threshhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def drop_long_traces(df,max_trace_len=64,event_id='event_id'):\n",
    "    df=df.drop(np.unique(df[df[event_id]>max_trace_len].index))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def RandomTraceSplitter(split_pct=0.2, seed=None):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(trace_ids):\n",
    "        o=np.unique(trace_ids)\n",
    "        np.random.seed(seed)\n",
    "        rand_idx = np.random.permutation(o)\n",
    "        cut = int(split_pct * len(o))\n",
    "        return L(rand_idx[cut:].tolist()),L(rand_idx[:cut].tolist())\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_traces(df,df_name='tmp',test_seed=42,validation_seed=None):\n",
    "    df=drop_long_traces(df)\n",
    "    ts=RandomTraceSplitter(seed=test_seed)\n",
    "    train,test=ts(df.index)\n",
    "    ts=RandomTraceSplitter(seed=validation_seed,split_pct=0.1)\n",
    "    train,valid=ts(train)\n",
    "    return train,valid,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "a1,b1,c1=split_traces(event_df)\n",
    "a2,b2,c2=split_traces(event_df)\n",
    "test_ne(a1,a2),test_ne(b1,b2),test_eq(c1,c2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activity</th>\n",
       "      <th>REG_DATE</th>\n",
       "      <th>AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 09:45:13.917000+00:00</td>\n",
       "      <td>W_Completeren aanvraag_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-10-01 10:17:08.924000+00:00</td>\n",
       "      <td>W_Nabellen offertes_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>2</td>\n",
       "      <td>10913.0</td>\n",
       "      <td>2011-10-08 14:32:00.886000+00:00</td>\n",
       "      <td>W_Nabellen offertes_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>3</td>\n",
       "      <td>11049.0</td>\n",
       "      <td>2011-10-10 09:33:05.791000+00:00</td>\n",
       "      <td>W_Nabellen offertes_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>4</td>\n",
       "      <td>10629.0</td>\n",
       "      <td>2011-10-13 08:37:37.026000+00:00</td>\n",
       "      <td>W_Valideren aanvraag_COMPLETE</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          event_id  resource                         timestamp  \\\n",
       "trace_id                                                         \n",
       "173688           0       NaN  2011-10-01 09:45:13.917000+00:00   \n",
       "173688           1       NaN  2011-10-01 10:17:08.924000+00:00   \n",
       "173688           2   10913.0  2011-10-08 14:32:00.886000+00:00   \n",
       "173688           3   11049.0  2011-10-10 09:33:05.791000+00:00   \n",
       "173688           4   10629.0  2011-10-13 08:37:37.026000+00:00   \n",
       "\n",
       "                                 activity                          REG_DATE  \\\n",
       "trace_id                                                                      \n",
       "173688    W_Completeren aanvraag_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688       W_Nabellen offertes_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688       W_Nabellen offertes_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688       W_Nabellen offertes_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "173688      W_Valideren aanvraag_COMPLETE  2011-10-01 00:38:44.546000+02:00   \n",
       "\n",
       "          AMOUNT_REQ  \n",
       "trace_id              \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  \n",
       "173688         20000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "event_df=import_log(EventLogs.BPIC_12_Wcomplete)\n",
    "event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9658, 9651)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "x=split_traces(event_df)\n",
    "(len(np.unique(event_df.index)),len(sum(x,[])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Techniques\n",
    "Categorization, Normalization, One-Hot, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### PPObj\n",
    "an object, that manages the pre-processing and knows date columns, cat columns and cont columns\n",
    "with a few convenient functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class _TraceIloc:\n",
    "    \"Get/set rows by iloc and cols by name\"\n",
    "    def __init__(self,o): self.o = o\n",
    "    def __getitem__(self, idxs):\n",
    "        df = self.o.items\n",
    "        if isinstance(idxs,tuple):\n",
    "            rows,cols = idxs\n",
    "            rows=df.index[rows]\n",
    "            return self.o.new(df.loc[rows,cols])\n",
    "        else:\n",
    "            rows,cols = idxs,slice(None)\n",
    "            rows=np.unique(df.index)[rows]\n",
    "            return self.o.new(df.loc[rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class PPObj(CollBase, GetAttr, FilteredBase):\n",
    "    \"Main Class for Process Prediction\"\n",
    "    _default,with_cont='procs',True\n",
    "    def __init__(self,df,procs=None,cat_names=None,cont_names=None,date_names=None,y_names=None,splits=None,\n",
    "                 ycat_names=None,ycont_names=None,inplace=False,do_setup=True):\n",
    "        if not inplace: df=df.copy()\n",
    "        if splits is not None: df = df.loc[sum(splits, [])] # Can drop traces\n",
    "        self.event_ids=df['event_id'].values if hasattr(df,'event_id') else None\n",
    "\n",
    "        super().__init__(df)\n",
    "\n",
    "        self.cat_names,self.cont_names,self.date_names=(L(cat_names),L(cont_names),L(date_names))\n",
    "        self.set_y_names(y_names,ycat_names,ycont_names)\n",
    "\n",
    "        self.procs = Pipeline(procs)\n",
    "        self.splits=splits\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "\n",
    "    @property\n",
    "    def y_names(self): return self.ycat_names+self.ycont_names\n",
    "\n",
    "    def set_y_names(self,y_names,ycat_names=None,ycont_names=None):\n",
    "        if ycat_names or ycont_names: store_attr('ycat_names,ycont_names')\n",
    "        else:\n",
    "            self.ycat_names,self.ycont_names=(L([i for i in L(y_names) if i in self.cat_names]),\n",
    "                                                L([i for i in L(y_names) if i not in self.cat_names]))\n",
    "    def setup(self): self.procs.setup(self)\n",
    "    def subset(self, i): return self.new(self.loc[self.splits[i]]) if self.splits else self\n",
    "    def __len__(self): return len(np.unique(self.items.index))\n",
    "    def show(self, max_n=3, **kwargs):\n",
    "        print('#traces:',len(self),'#events:',len(self.items))\n",
    "        display_df(self.new(self.all_cols[:max_n]).items)\n",
    "    def new(self, df):\n",
    "        return type(self)(df, do_setup=False,\n",
    "                          **attrdict(self, 'procs','cat_names','cont_names','ycat_names','ycont_names',\n",
    "                                     'date_names'))\n",
    "    def process(self): self.procs(self)\n",
    "    def loc(self): return self.items.loc\n",
    "    def iloc(self): return _TraceIloc(self)\n",
    "    def x_names (self): return self.cat_names + self.cont_names\n",
    "    def all_col_names(self): return ((self.x_names+self.y_names)).unique()\n",
    "    def transform(self, cols, f, all_col=True):\n",
    "        if not all_col: cols = [c for c in cols if c in self.items.columns]\n",
    "        if len(cols) > 0: self[cols] = self[cols].transform(f)\n",
    "    def new_empty(self): return self.new(pd.DataFrame({}, columns=self.items.columns))\n",
    "    def subsets(self): return [self.subset(i) for i in range(len(self.splits))] if self.splits else L(self)\n",
    "properties(PPObj,'loc','iloc','x_names','all_col_names')\n",
    "\n",
    "def _add_prop(cls, nm):\n",
    "    @property\n",
    "    def f(o): return o[list(getattr(o,nm+'_names'))]\n",
    "    @f.setter\n",
    "    def fset(o, v): o[getattr(o,nm+'_names')] = v\n",
    "    setattr(cls, nm+'s', f)\n",
    "    setattr(cls, nm+'s', fset)\n",
    "\n",
    "_add_prop(PPObj, 'cat')\n",
    "_add_prop(PPObj, 'cont')\n",
    "_add_prop(PPObj, 'ycat')\n",
    "_add_prop(PPObj, 'ycont')\n",
    "_add_prop(PPObj, 'y')\n",
    "_add_prop(PPObj, 'x')\n",
    "_add_prop(PPObj, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ppObj=PPObj(event_df,cat_names=['activity', 'resource'],y_names=['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) ['activity']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppObj.ycat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 1 #events: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>resource</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>W_Completeren aanvraag_COMPLETE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>W_Nabellen offertes_COMPLETE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>W_Nabellen offertes_COMPLETE</td>\n",
       "      <td>10913.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ppObj.iloc[0].show() # shows first trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can define various pre-processing functions that are executed, when `PPOBj` is instantiated. `PPProc` is the base class for a pre-processing function. It ensures, that setup of a pre-processing function is performed using the training set, and than it is applied to the validation and test set, with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class PPProc(InplaceTransform):\n",
    "    \"Base class to write a non-lazy tabular processor for dataframes\"\n",
    "    def setup(self, items=None, train_setup=False): #TODO: properly deal with train_setup\n",
    "        super().setup(getattr(items,'train',items), train_setup=False)\n",
    "        #super().setup(items, train_setup=False)\n",
    "\n",
    "        # Procs are called as soon as data is available\n",
    "        return self(items.items if isinstance(items,Datasets) else items)\n",
    "\n",
    "    @property\n",
    "    def name(self): return f\"{super().name} -- {getattr(self,'__stored_args__',{})}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Categorization\n",
    "i.e ordinal encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Implementation of ordinal or integer encoding. Adds NA values for unknown data. Implementation is pretty much taken from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _apply_cats (voc, add, c):\n",
    "    if not is_categorical_dtype(c):\n",
    "        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add\n",
    "    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Categorify(PPProc):\n",
    "    \"Transform the categorical variables to something similar to `pd.Categorical`\"\n",
    "    order = 2\n",
    "    def setups(self, to):\n",
    "        store_attr(classes={n:CategoryMap(to.items.loc[:,n], add_na=True) for n in to.cat_names}, but='to')\n",
    "    def encodes(self, to):\n",
    "        to.transform(to.cat_names, partial(_apply_cats, self.classes, 1))\n",
    "    def __getitem__(self,k): return self.classes[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log=import_log(EventLogs.BPIC_12)\n",
    "traces=split_traces(log)[0][:100]\n",
    "splits=traces[:60],traces[60:80],traces[80:100]\n",
    "o=PPObj(log,None,cat_names='activity',splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=CategoryMap(o.items.loc[:,'activity'])\n",
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat=Categorify()\n",
    "cat.setup(o)\n",
    "len(cat['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 5 #events: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[0,1,2,0,2]})\n",
    "to = PPObj(df, Categorify, 'a')\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log=import_log(EventLogs.BPIC_12)\n",
    "o=PPObj(log,Categorify,'activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fill Missing\n",
    "for continuous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A pre-processing function that deals with missing data in continuous attributes. Missing data can be replaced with the median, mean or a constant value. Additionaly, we can create another boolean column that indicates, which rows were missing.  Implementation is pretty much taken from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class FillStrategy:\n",
    "    \"Namespace containing the various filling strategies.\"\n",
    "    def median  (c,fill): return c.median()\n",
    "    def constant(c,fill): return fill\n",
    "    def mode    (c,fill): return c.dropna().value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class FillMissing(PPProc):\n",
    "    order=1\n",
    "    \"Fill the missing values in continuous columns.\"\n",
    "    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):\n",
    "        if fill_vals is None: fill_vals = defaultdict(int)\n",
    "        store_attr()\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        missing = pd.isnull(dsets.conts).any()\n",
    "        store_attr(but='to', na_dict={n:self.fill_strategy(dsets[n], self.fill_vals[n])\n",
    "                            for n in missing[missing].keys()})\n",
    "        self.fill_strategy = self.fill_strategy.__name__\n",
    "\n",
    "    def encodes(self, to):\n",
    "        missing = pd.isnull(to.conts)\n",
    "        for n in missing.any()[missing.any()].keys():\n",
    "            assert n in self.na_dict, f\"nan values in `{n}` but not in setup training set\"\n",
    "        for n in self.na_dict.keys():\n",
    "            to[n].fillna(self.na_dict[n], inplace=True)\n",
    "            if self.add_col:\n",
    "                to.loc[:,n+'_na'] = missing[n]\n",
    "                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 7 #events: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_na</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fill = FillMissing() \n",
    "df = pd.DataFrame({'a':[0,1,np.nan,1,2,3,4], 'b': [0,1,2,3,4,5,6]})\n",
    "to = PPObj(df, fill, cont_names=['a', 'b'])\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculates standartization, also known as z-score formula. Copied from fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Normalize(PPProc):\n",
    "    \"Normalize with z-score\"\n",
    "    order = 3\n",
    "    def setups(self, to):\n",
    "        store_attr(but='to', means=dict(getattr(to, 'train', to).conts.mean()),\n",
    "                   stds=dict(getattr(to, 'train', to).conts.std(ddof=0)+1e-7))\n",
    "        return self(to)\n",
    "\n",
    "    def encodes(self, to): to.conts = (to.conts-self.means) / self.stds\n",
    "    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>activity</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>cost</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>resource</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>pay expenses_start</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FI12</td>\n",
       "      <td>167.52</td>\n",
       "      <td>2017-01-16 12:29:00+00:00</td>\n",
       "      <td>FI12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pay expenses_complete</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>FI12</td>\n",
       "      <td>167.52</td>\n",
       "      <td>2017-01-16 12:40:00+00:00</td>\n",
       "      <td>FI12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>pay expenses_start</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>JH2172</td>\n",
       "      <td>262.11</td>\n",
       "      <td>2017-01-16 07:38:00+00:00</td>\n",
       "      <td>JH2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>pay expenses_complete</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>JH2172</td>\n",
       "      <td>262.11</td>\n",
       "      <td>2017-01-16 07:48:00+00:00</td>\n",
       "      <td>JH2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>calculate payments_start</td>\n",
       "      <td>Accounting</td>\n",
       "      <td>WE5108</td>\n",
       "      <td>413.14</td>\n",
       "      <td>2017-01-04 05:59:00+00:00</td>\n",
       "      <td>WE5108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          event_id                  activity        type    user    cost  \\\n",
       "trace_id                                                                   \n",
       "1                0        pay expenses_start  Accounting    FI12  167.52   \n",
       "1                1     pay expenses_complete  Accounting    FI12  167.52   \n",
       "5                0        pay expenses_start  Accounting  JH2172  262.11   \n",
       "5                1     pay expenses_complete  Accounting  JH2172  262.11   \n",
       "6                0  calculate payments_start  Accounting  WE5108  413.14   \n",
       "\n",
       "                          timestamp resource  \n",
       "trace_id                                      \n",
       "1         2017-01-16 12:29:00+00:00     FI12  \n",
       "1         2017-01-16 12:40:00+00:00     FI12  \n",
       "5         2017-01-16 07:38:00+00:00   JH2172  \n",
       "5         2017-01-16 07:48:00+00:00   JH2172  \n",
       "6         2017-01-04 05:59:00+00:00   WE5108  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 5 #events: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.429409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.327783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.514775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'a':[0,1,9,3,4]})\n",
    "to = PPObj(df, Normalize(), cont_names='a')\n",
    "to.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Date conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Encodes a date column. Supports multiple information by using pandas date functions. This implementation is also based on the fastai but also supports relative duration from the first event of a case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_date(df, date_field):\n",
    "    \"Make sure `df[date_field]` is of the right date type.\"\n",
    "    field_dtype = df[date_field].dtype\n",
    "    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        field_dtype = np.datetime64\n",
    "    if not np.issubdtype(field_dtype, np.datetime64):\n",
    "        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True,utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fu    datetime64[ns, UTC]\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n",
    "_make_date(df, 'fu')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _secSinceSunNoon(datTimStr):\n",
    "    dt = pd.to_datetime(datTimStr).dt\n",
    "    return (dt.dayofweek-1)*24*3600+ dt.hour * 3600 + dt.minute * 60 + dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _secSinceNoon(datTimStr):\n",
    "    dt = pd.to_datetime(datTimStr).dt\n",
    "    return dt.hour * 3600 + dt.minute * 60 + dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "Base_Date_Encodings=['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear','Elapsed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def encode_date(df, field_name,unit=1e9,date_encodings=Base_Date_Encodings):\n",
    "    \"Helper function that adds columns relevant to a date in the column `field_name` of `df`.\"\n",
    "    _make_date(df, field_name)\n",
    "    field = df[field_name]\n",
    "    prefix =  re.sub('[Dd]ate$', '', field_name+\"_\")\n",
    "    attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',\n",
    "            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr:\n",
    "        if n in date_encodings: df[prefix + n] = getattr(field.dt, n.lower())\n",
    "    # Pandas removed `dt.week` in v1.1.10\n",
    "\n",
    "    if 'secSinceSunNoon' in date_encodings:\n",
    "        df[prefix+'secSinceSunNoon']=_secSinceSunNoon(field)\n",
    "    if 'secSinceNoon' in date_encodings:\n",
    "        df[prefix+'secSinceNoon']=_secSinceNoon(field)\n",
    "    if 'Week' in date_encodings:\n",
    "        week = field.dt.isocalendar().week if hasattr(field.dt, 'isocalendar') else field.dt.week\n",
    "        df.insert(3, prefix+'Week', week)\n",
    "    mask = ~field.isna()\n",
    "    elapsed = pd.Series(np.where(mask,field.values.astype(np.int64) // unit,None).astype(float),index=field.index)\n",
    "\n",
    "    if 'Relative_elapsed' in date_encodings:\n",
    "        df[prefix+'Relative_elapsed']=elapsed-elapsed.groupby(elapsed.index).transform('min')\n",
    "\n",
    "    # required to decode!\n",
    "    if 'Elapsed' in date_encodings: df[prefix+'Elapsed']=elapsed\n",
    "\n",
    "    df.drop(field_name, axis=1, inplace=True)\n",
    "    return [],[prefix+i for i in date_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu_Year</th>\n",
       "      <th>fu_Month</th>\n",
       "      <th>fu_Day</th>\n",
       "      <th>fu_Dayofweek</th>\n",
       "      <th>fu_Dayofyear</th>\n",
       "      <th>fu_Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>338</td>\n",
       "      <td>1.575418e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>333</td>\n",
       "      <td>1.574986e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>319</td>\n",
       "      <td>1.573776e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>1.571875e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fu_Year  fu_Month  fu_Day  fu_Dayofweek  fu_Dayofyear    fu_Elapsed\n",
       "0     2019        12       4             2           338  1.575418e+09\n",
       "1     2019        11      29             4           333  1.574986e+09\n",
       "2     2019        11      15             4           319  1.573776e+09\n",
       "3     2019        10      24             3           297  1.571875e+09"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-12-04', '2019-11-29', '2019-11-15', '2019-10-24']})\n",
    "encode_date(df,'fu')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def decode_date(df, field_name,unit=1e9,date_encodings=Base_Date_Encodings):\n",
    "    df[field_name]=(df[field_name+'_'+'Elapsed'] * unit).astype('datetime64[ns, UTC]')\n",
    "    for c in date_encodings: del df[field_name+'_'+c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-04 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-29 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-15 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-24 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fu\n",
       "0 2019-12-04 00:00:00+00:00\n",
       "1 2019-11-29 00:00:00+00:00\n",
       "2 2019-11-15 00:00:00+00:00\n",
       "3 2019-10-24 00:00:00+00:00"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_date(df,'fu')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class Datetify(PPProc):\n",
    "    \"Encode dates, \"\n",
    "    order = 0\n",
    "\n",
    "    def __init__(self, date_encodings=['Relative_elapsed']): self.date_encodings=listify(date_encodings)\n",
    "\n",
    "    def encodes(self, o):\n",
    "        for i in o.date_names:\n",
    "            cat,cont=encode_date(o.items,i,date_encodings=self.date_encodings)\n",
    "            o.cont_names+=cont\n",
    "            o.cat_names+=cat\n",
    "# Todo: Add decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fu_secSinceSunNoon</th>\n",
       "      <th>fu_secSinceNoon</th>\n",
       "      <th>fu_Relative_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86400</td>\n",
       "      <td>0</td>\n",
       "      <td>432000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>950400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172800</td>\n",
       "      <td>0</td>\n",
       "      <td>1728000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fu_secSinceSunNoon  fu_secSinceNoon  fu_Relative_elapsed\n",
       "1              259200                0                  0.0\n",
       "1               86400                0             432000.0\n",
       "1                   0                0             950400.0\n",
       "1              172800                0            1728000.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fu': ['2019-10-04', '2019-10-09', '2019-10-15', '2019-10-24']},index=[1,1,1,1])\n",
    "o = PPObj(df,Datetify(date_encodings=['secSinceSunNoon','secSinceNoon','Relative_elapsed']),date_names='fu')\n",
    "o.xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MinMax Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculates the MinMax scaling from a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class MinMax(PPProc):\n",
    "    order=3\n",
    "\n",
    "    def setups(self, o):\n",
    "        store_attr(mins=o.xs.min(),\n",
    "                   maxs=o.xs.max())\n",
    "\n",
    "    def encodes(self, o):\n",
    "        cols=[i+'_minmax' for i in o.x_names]\n",
    "        o[cols] = o.xs.astype(float)\n",
    "        o[cols] = ((o.xs-self.mins) /(self.maxs-self.mins))\n",
    "        o.cont_names=L(cols)\n",
    "        o.cat_names=L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_df=import_log(EventLogs.Mobis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "o=PPObj(event_df,[Categorify,MinMax,Datetify,FillMissing],cont_names=['cost'],cat_names=['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_minmax    1.0\n",
       "cost_na_minmax     1.0\n",
       "cost_minmax        1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.xs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_df=import_log(EventLogs.BPIC_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 13087 #events: 262200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_minmax</th>\n",
       "      <th>resource_minmax</th>\n",
       "      <th>AMOUNT_REQ_minmax</th>\n",
       "      <th>timestamp_Relative_elapsed_minmax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173688</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200002</td>\n",
       "      <td>0.003330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPObj(event_df,[Categorify(),Datetify(),MinMax()],\n",
    "      date_names=['timestamp'],cat_names=['activity','resource'],cont_names=['AMOUNT_REQ']).show(max_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### One HoT Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculates the one-hot encoding of a column. It is required to first apply categorization on the same column, to deal with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "o=PPObj(event_df,[Categorify],cat_names=['activity','resource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262200, 37)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o.xs),len(o.procs.categorify['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  1],\n",
       "       [ 7,  1],\n",
       "       [ 8,  1],\n",
       "       ...,\n",
       "       [20, 49],\n",
       "       [ 5, 49],\n",
       "       [18, 49]], dtype=int8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.xs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x=o.xs.to_numpy()\n",
    "categories=[range(len(o.procs.categorify['activity'])),range(len(o.procs.categorify['activity']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x=np.array(['a1','a2'])\n",
    "categories=[['a1','a2','a3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(categories=categories)\n",
    "a=ohe.fit_transform(x.reshape(-1, 1)).toarray()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categories=['a1','a2','a3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class OneHot(PPProc):\n",
    "    \"Transform the categorical variables to one-hot. Requires Categorify to deal with unseen data.\"\n",
    "    order = 3\n",
    "\n",
    "    def encodes(self, o):\n",
    "        new_cats=[]\n",
    "        for c in o.cat_names:\n",
    "            categories=[range(len(o.procs.categorify[c]))]\n",
    "            x=o[c].to_numpy()\n",
    "            ohe = OneHotEncoder(categories=categories)\n",
    "            enc=ohe.fit_transform(x.reshape(-1, 1)).toarray()\n",
    "            for i in range(enc.shape[1]):\n",
    "                new_cat=f'{c}_{i}'\n",
    "                o.items.loc[:,new_cat]=enc[:,i]\n",
    "                new_cats.append(new_cat)\n",
    "        o.cat_names=L(new_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_df=import_log(EventLogs.BPIC_17_OFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 407 ms, sys: 136 ms, total: 543 ms\n",
      "Wall time: 543 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "o=PPObj(event_df,[Categorify(),OneHot()],cat_names=['activity','resource'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sub-sequence Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here, the log dataframe is converted into subsequences or prefices of the cases. For a case with n events, we create n prefixes. The prefix generation is done in an efficient way, through the `np.roll` function, which shifts a numpy array by 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def _shift_columns (a,ws=3): return np.dstack(list(reversed([np.roll(a,i) for i in range(0,ws)])))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def subsequences_fast(df,event_ids,ws=None,min_ws=64):\n",
    "    max_trace_len=int(event_ids.max())+1\n",
    "\n",
    "    if not ws: ws=max_trace_len-1\n",
    "    elif ws <max_trace_len-1: raise ValueError(f\"ws must be greater equal {max_trace_len-1}\")\n",
    "    pad=ws\n",
    "    ws=max(min_ws,ws)\n",
    "    trace_start = np.where(event_ids == 0)[0]\n",
    "    trace_len=np.array([trace_start[i]-trace_start[i-1] for i in range(1,len(trace_start))]+[len(df)-trace_start[-1]])\n",
    "    tmp=np.stack([_shift_columns(df[i],ws=ws) for i in list(df)])\n",
    "    idx=[range(trace_start[i],trace_start[i]+trace_len[i]-1) for i in range(len(trace_start))]\n",
    "    idx=np.array([y for x in idx for y in x])\n",
    "\n",
    "    res=np.rollaxis(tmp,1)[idx]\n",
    "    mask=ws-1-event_ids[idx][:,None] > np.arange(res.shape[2])\n",
    "    res[np.broadcast_to(mask[:,None],res.shape)]=0\n",
    "    return res,idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "event_df=import_log(EventLogs.Helpdesk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4580"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity','resource'],y_names='activity')\n",
    "#o=o.iloc[0]\n",
    "len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16768"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o.items)-len(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  0,  0, ...,  0,  0,  1],\n",
       "         [ 0,  0,  0, ...,  0,  0,  1]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  1, 12],\n",
       "         [ 0,  0,  0, ...,  0,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  1, 12, 12],\n",
       "         [ 0,  0,  0, ...,  1,  1, 12]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  0, 12],\n",
       "         [ 0,  0,  0, ...,  0,  0, 19]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0, 12, 14],\n",
       "         [ 0,  0,  0, ...,  0, 19, 19]],\n",
       " \n",
       "        [[ 0,  0,  0, ..., 12, 14, 10],\n",
       "         [ 0,  0,  0, ..., 19, 19, 19]]], dtype=int8),\n",
       " (16768, 2, 14))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws,idx=subsequences_fast(o.xs,o.event_ids,min_ws=14)\n",
    "ws,ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prefixes are converted to a `pytorch.Dataset` and than to a `DataLoader`\n",
    "A batch is than represented as a tuple of the form `(x cat. attr,x cont. attr, y cat. attr., y cont attr.)`. Also, categorical attributes are converted to a long tensor and continous attributes to a float tensor.\n",
    "\n",
    "If a dimensions of the batch is empty - e.g. the model does not use categorical input attributes - it is removed from the tuple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 0,  0,  0, ...,  0,  0,  1],\n",
       "         [ 0,  0,  0, ...,  0,  0,  1]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  1, 12],\n",
       "         [ 0,  0,  0, ...,  0,  1,  1]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  1, 12, 12],\n",
       "         [ 0,  0,  0, ...,  1,  1, 12]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0,  0, 12],\n",
       "         [ 0,  0,  0, ...,  0,  0, 19]],\n",
       " \n",
       "        [[ 0,  0,  0, ...,  0, 12, 14],\n",
       "         [ 0,  0,  0, ...,  0, 19, 19]],\n",
       " \n",
       "        [[ 0,  0,  0, ..., 12, 14, 10],\n",
       "         [ 0,  0,  0, ..., 19, 19, 19]]], dtype=int8),\n",
       " (16768, 2, 14))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity','resource'],y_names='activity')\n",
    "ws,idx=subsequences_fast(o.xs,o.event_ids,min_ws=14)\n",
    "ws,ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14], dtype=int8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.ys.iloc[idx].values[16765]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       ...,\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]], dtype=int8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.ys.groupby(o.items.index).transform('last').iloc[idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not outcome: y=o.ys.iloc[idx]\n",
    "else: y=o.ys.groupby(o.items.index).transform('last').iloc[idx]\n",
    "ycats=tensor(y[o.ycat_names].values).long()\n",
    "yconts=tensor(y[o.ycont_names].values).float()\n",
    "xcats=tensor(ws[:,len(o.cat_names):]).float()\n",
    "xconts=tensor(ws[:,:len(o.cat_names)]).long()\n",
    "xs=tuple([i for i in [xcats,xconts] if i.shape[1]>0])\n",
    "ys=tuple([ycats[:,i] for i in range(ycats.shape[1])])+tuple([yconts[:,i] for i in range(yconts.shape[1])])\n",
    "res=(*xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 12, 10,  ..., 14, 10,  2]),)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PPDset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inp):\n",
    "        store_attr('inp')\n",
    "\n",
    "    def __len__(self): return len(self.inp[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        xs=tuple([i[idx]for i in self.inp[:-1]])\n",
    "        ys=tuple([i[idx]for i in self.inp[-1]])\n",
    "        if len(ys)==1: ys=ys[0]\n",
    "        return (*xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=DataLoaders.from_dsets(PPDset(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2, 14]), torch.Size([64]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xcat,y=dls.one_batch()\n",
    "xcat.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=PPObj(event_df,Categorify(),cat_names=['activity','resource'],y_names='activity',splits=split_traces(event_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) ['activity','resource']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TfmdDL)\n",
    "def get_dls(ppo:PPObj,windows=subsequences_fast,outcome=False,event_id='event_id',bs=64,**kwargs):\n",
    "    ds=[]\n",
    "    for s in ppo.subsets():\n",
    "        wds,idx=windows(s.xs,s.event_ids)\n",
    "\n",
    "        if not outcome: y=s.ys.iloc[idx]\n",
    "        else: y=s.ys.groupby(s.items.index).transform('last').iloc[idx]\n",
    "        ycats=tensor(y[s.ycat_names].values).long()\n",
    "        yconts=tensor(y[s.ycont_names].values).float()\n",
    "        xconts=tensor(wds[:,len(s.cat_names):]).float()\n",
    "        xcats=tensor(wds[:,:len(s.cat_names)]).long()\n",
    "        xs=tuple([i.squeeze() for i in [xcats,xconts] if i.shape[1]>0])\n",
    "        ys=tuple([ycats[:,i] for i in range(ycats.shape[1])])+tuple([yconts[:,i] for i in range(yconts.shape[1])])\n",
    "        ds.append(PPDset((*xs,ys)))\n",
    "    return DataLoaders.from_dsets(*ds,bs=bs,**kwargs)\n",
    "PPObj.get_dls= get_dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2, 64]), torch.Size([64]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls=o.get_dls()\n",
    "xb,yb=dls.one_batch()\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section shows, how the PPObj can be used to create a DataLoader for pedictive process analytics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next event prediction:  \n",
    "X: 'activity'   \n",
    "Y: 'activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case3785</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case3785</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 14]), torch.Size([64]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,Categorify(),cat_names=['activity'],y_names='activity',splits=split_traces(event_df))\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0))\n",
    "o.show(max_n=2)\n",
    "xb,y=dls.one_batch()\n",
    "xb.shape,y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next event prediction:  \n",
    "X: 'activity','resource','duration'   \n",
    "Y: 'activity'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp_Relative_elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case170</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.789946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case170</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.751444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 17]]),\n",
       " tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.7899]),\n",
       " tensor(12))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,[Categorify(),Datetify(),Normalize()],cat_names=['activity','resource'],date_names=['timestamp'],y_names='activity',splits=split_traces(event_df))\n",
    "o.show(max_n=2)\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0))\n",
    "xcat,xcont,y=dls.one_batch()\n",
    "xcat[-1],xcont[-1],y[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next event prediction:  \n",
    "X: 'activity','resource','duration'   \n",
    "Y: 'activity','resource','duration'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp_Relative_elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case579</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.787562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case579</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.787555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 12,  8, 10],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 12,  5, 12]]),\n",
       " tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.7876, -0.7390, -0.4320,  1.4882]),\n",
       " tensor(2),\n",
       " tensor(16),\n",
       " tensor(2.3610))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,[Categorify(),Datetify(),Normalize()],cat_names=['activity','resource'],date_names=['timestamp'],\n",
    "        y_names=['activity','resource','timestamp_Relative_elapsed'],splits=split_traces(event_df))\n",
    "o.show(max_n=2)\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0))\n",
    "x=dls.one_batch()\n",
    "xcat,xcont,y=dls.one_batch()\n",
    "xcat[-1],xcont[-1],y[0][-1],y[1][-1],y[2][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome prediction:  \n",
    "X:'activity','resource','duration'  \n",
    "Y:'activity','resource','duration'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>resource</th>\n",
       "      <th>timestamp_Relative_elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case338</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.788453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case338</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.731482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 12, 12],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 21, 21, 22]]),\n",
       " tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.7885, -0.7884, -0.7878]),\n",
       " tensor(2),\n",
       " tensor(18),\n",
       " tensor(1.9353))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,[Categorify(),Datetify(),Normalize()],cat_names=['activity','resource'],date_names=['timestamp'],\n",
    "        y_names=['activity','resource','timestamp_Relative_elapsed'],splits=split_traces(event_df))\n",
    "o.show(max_n=2)\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0),outcome=True)\n",
    "xcat,xcont,y=dls.one_batch()\n",
    "xcat[-1],xcont[-1],y[0][-1],y[1][-1],y[2][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome prediction with One-Hot-Encoding  \n",
    "X:'activity','resource'  \n",
    "Y:'activity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_0</th>\n",
       "      <th>activity_1</th>\n",
       "      <th>activity_2</th>\n",
       "      <th>activity_3</th>\n",
       "      <th>activity_4</th>\n",
       "      <th>activity_5</th>\n",
       "      <th>activity_6</th>\n",
       "      <th>activity_7</th>\n",
       "      <th>activity_8</th>\n",
       "      <th>activity_9</th>\n",
       "      <th>activity_10</th>\n",
       "      <th>activity_11</th>\n",
       "      <th>activity_12</th>\n",
       "      <th>activity_13</th>\n",
       "      <th>activity_14</th>\n",
       "      <th>resource_0</th>\n",
       "      <th>resource_1</th>\n",
       "      <th>resource_2</th>\n",
       "      <th>resource_3</th>\n",
       "      <th>resource_4</th>\n",
       "      <th>resource_5</th>\n",
       "      <th>resource_6</th>\n",
       "      <th>resource_7</th>\n",
       "      <th>resource_8</th>\n",
       "      <th>resource_9</th>\n",
       "      <th>resource_10</th>\n",
       "      <th>resource_11</th>\n",
       "      <th>resource_12</th>\n",
       "      <th>resource_13</th>\n",
       "      <th>resource_14</th>\n",
       "      <th>resource_15</th>\n",
       "      <th>resource_16</th>\n",
       "      <th>resource_17</th>\n",
       "      <th>resource_18</th>\n",
       "      <th>resource_19</th>\n",
       "      <th>resource_20</th>\n",
       "      <th>resource_21</th>\n",
       "      <th>resource_22</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case2186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case2186</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 38, 14]), torch.Size([64]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,[Categorify(),Datetify(),OneHot()],cat_names=['activity','resource'],y_names='activity',splits=split_traces(event_df))\n",
    "o.show(max_n=2)\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0),outcome=True)\n",
    "xcat,y=dls.one_batch()\n",
    "xcat.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome prediction with Min-Max-Scaling  \n",
    "X:'activity','resource','duration'  \n",
    "Y:'activity','resource','duration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#traces: 4580 #events: 21348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_minmax</th>\n",
       "      <th>resource_minmax</th>\n",
       "      <th>timestamp_Relative_elapsed_minmax</th>\n",
       "      <th>timestamp_Relative_elapsed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trace_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Case4559</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case4559</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 38, 14]),\n",
       " torch.Size([64, 3, 14]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log=import_log(EventLogs.Helpdesk)\n",
    "o=PPObj(log,[Categorify(),Datetify(),MinMax()],cat_names=['activity','resource'],date_names=['timestamp'],\n",
    "        y_names=['activity_minmax','resource_minmax','timestamp_Relative_elapsed'],splits=split_traces(event_df))\n",
    "o.show(max_n=2)\n",
    "dls=o.get_dls(windows=partial(subsequences_fast,min_ws=0),outcome=True)\n",
    "xcont,y=dls.one_batch()\n",
    "xcat.shape,xcont.shape,y[0].shape,y[1].shape,y[2].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mppn",
   "language": "python",
   "name": "mppn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
