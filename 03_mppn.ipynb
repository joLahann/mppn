{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Models</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#PPM\" data-toc-modified-id=\"PPM-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>PPM</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp mppn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPPN\n",
    "===\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes the implementation of the `MPPN` as described in the paper. It includes the pytorch models, a training procedure containing pre-processing and data loader generation, the implementation of the `PPModel` based on MPPN's pytorch models for each process prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mppn.imports import *\n",
    "from mppn.preprocessing import *\n",
    "from mppn.pipeline import *\n",
    "from mppn.baselines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RUN_TRAINING=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class BaseMPPN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_perspectives, feature_size=64, output_dim=128):\n",
    "        super(BaseMPPN, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.output_dim = output_dim\n",
    "        self.mode = 99\n",
    "        self.stop_training = False\n",
    "\n",
    "        if self.mode == 1:\n",
    "            self.num_perspectives = 1\n",
    "        else:\n",
    "            self.num_perspectives = num_perspectives\n",
    "\n",
    "        self.CNN = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=self.feature_size, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.num_perspectives * self.feature_size, self.num_perspectives * self.feature_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.num_perspectives * self.feature_size, self.num_perspectives * int(self.feature_size)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.num_perspectives * int(self.feature_size), self.output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        view_pool = []\n",
    "\n",
    "        for v in x:\n",
    "            \"\"\"size of v: [batch_size, 3, img_height, img_width]\"\"\"\n",
    "            \"\"\"Get features from GAFs using CNN\"\"\"\n",
    "            v = self.CNN(v)\n",
    "            \"\"\"size of v: [batch_size, feature_size, ?, ?], last two should be 1, 1\"\"\"\n",
    "            \"\"\"Reduce dimensions from 4 to 2 (first is batchsize)\"\"\"\n",
    "            v = v.view(v.size(0), self.feature_size)\n",
    "\n",
    "\n",
    "            view_pool.append(v)\n",
    "\n",
    "\n",
    "        pooled_view = view_pool[0]\n",
    "        \"\"\"Max-pooling of all views\"\"\"\n",
    "        if self.mode == 1:\n",
    "            for i in range(1, len(view_pool)):\n",
    "                pooled_view = torch.max(pooled_view, view_pool[i])\n",
    "\n",
    "        else:\n",
    "            \"\"\"Concatenate features from all perspectives\"\"\"\n",
    "            pooled_view = torch.cat(view_pool, dim=1)\n",
    "\n",
    "        \"\"\"Get representation from MLP\"\"\"\n",
    "        representation = self.MLP(pooled_view)\n",
    "\n",
    "        return representation\n",
    "\n",
    "    def count_parameters(self):\n",
    "\n",
    "        param_CNN = sum(p.numel() for p in self.MLP.parameters() if p.requires_grad)\n",
    "        param_MLP = sum(p.numel() for p in self.MLP.parameters() if p.requires_grad)\n",
    "\n",
    "        params = param_CNN + param_MLP\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MPPNClassifier(BaseMPPN):\n",
    "    \"\"\"\n",
    "    Extends Base MPPN with one classification layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_perspectives, num_classes, feature_size=64, output_dim=128,with_softmax=True):\n",
    "        super().__init__(num_perspectives, feature_size=feature_size, output_dim=output_dim)\n",
    "        self.with_softmax=num_classes!=1\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(output_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        representation = BaseMPPN.forward(self, x)\n",
    "        classifier_output = self.classification(representation)\n",
    "        if self.with_softmax:\n",
    "            classifier_output=F.log_softmax(classifier_output,dim=1)\n",
    "        return classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class MPPNMultitask(BaseMPPN):\n",
    "    \"\"\"\n",
    "    Extends the MPPNClassifier with multiple heads to predict multiple outputs at once.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_perspectives, output_attr, feature_size=64, representation_dim=128):\n",
    "        super().__init__(num_perspectives, feature_size=feature_size, output_dim=representation_dim)\n",
    "        del self.MLP\n",
    "\n",
    "        self.output_attr = output_attr\n",
    "        self.representation_dim = representation_dim\n",
    "\n",
    "        \"\"\"Get the output dimension of the CNN\"\"\"\n",
    "        self.CNN_out_dim = self.CNN[-3].out_channels\n",
    "\n",
    "        self.MLP = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.num_perspectives * self.feature_size, self.num_perspectives * int(self.feature_size/2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.num_perspectives * int(self.feature_size/2), self.representation_dim),\n",
    "        )\n",
    "\n",
    "        \"\"\"Dynamically create heads for each attribute to predict\"\"\"\n",
    "        self.output_attr = self.output_attr\n",
    "        self.heads = nn.ModuleList()\n",
    "        for attr_name, output_dim in self.output_attr.items():\n",
    "            #print(\"Head\", attr_name)\n",
    "            self.heads.append(self.create_head(output_dim))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.transpose(0, 1)\n",
    "\n",
    "        view_pool = []\n",
    "\n",
    "        for v in x:\n",
    "            \"\"\"size of v: [batch_size, 3, img_height, img_width]\"\"\"\n",
    "            \"\"\"Get features from GAFs using CNN\"\"\"\n",
    "            v = self.CNN(v)\n",
    "            \"\"\"size of v: [batch_size, feature_size, ?, ?], last two should be 1, 1\"\"\"\n",
    "            \"\"\"Reduce dimensions from 4 to 2 (first is batchsize)\"\"\"\n",
    "            v = v.view(v.size(0), self.feature_size)\n",
    "\n",
    "            view_pool.append(v)\n",
    "\n",
    "        pooled_view = view_pool[0]\n",
    "        \"\"\"Max-pooling of all views\"\"\"\n",
    "        if self.mode == 1:\n",
    "            for i in range(1, len(view_pool)):\n",
    "                pooled_view = torch.max(pooled_view, view_pool[i])\n",
    "\n",
    "        else:\n",
    "            \"\"\"Concatenate features from all perspectives\"\"\"\n",
    "            pooled_view = torch.cat(view_pool, dim=1)\n",
    "\n",
    "        shared = self.MLP(pooled_view)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        \"\"\"Predict each attribute\"\"\"\n",
    "        for head in self.heads:\n",
    "            if head[-1].out_features > 1:\n",
    "                outputs.append(F.log_softmax(head(shared), dim=1))\n",
    "            else:\n",
    "                outputs.append(head(shared))\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def create_head(self, num_classes):\n",
    "        \"\"\"Create a head, i.e. a subnetwork to predict a certain attribute in multi-task fashion\"\"\"\n",
    "        head = nn.Sequential(\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(self.representation_dim, self.representation_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.representation_dim, num_classes)\n",
    "        )\n",
    "\n",
    "        return head\n",
    "\n",
    "    def count_parameters(self):\n",
    "\n",
    "        param_CNN = sum(p.numel() for p in self.MLP.parameters() if p.requires_grad)\n",
    "        param_MLP = sum(p.numel() for p in self.MLP.parameters() if p.requires_grad)\n",
    "        param_heads = sum(p.numel() for head in self.heads for p in head.parameters() if p.requires_grad)\n",
    "\n",
    "        params = param_CNN + param_MLP + param_heads\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def load_checkpoint(path, filename):\n",
    "    \"\"\"\n",
    "    Load checkpoint from disk\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path\n",
    "    filename\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    loadpath = os.path.join(path, filename + '_checkpoint.pth.tar')\n",
    "\n",
    "    assert os.path.isfile(loadpath), 'Error: no checkpoint file found!'\n",
    "\n",
    "    checkpoint = torch.load(loadpath)\n",
    "\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "model_urls = {\n",
    "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "}\n",
    "\n",
    "def mppn_pretraining_model(pretrained=False, **kwargs):\n",
    "    \"\"\"Returns a model either pretrained as alexnet or on GAF images.\"\"\"\n",
    "    model = MPPNClassifier(**kwargs)\n",
    "\n",
    "    pretrained_model = \"alexnet\"\n",
    "\n",
    "    if pretrained:\n",
    "        if pretrained_model == \"alexnet\":\n",
    "            print(\"Loading Alexnet to train MPPNs CNN from scratch\")\n",
    "            pretrained_dict = model_zoo.load_url(model_urls['alexnet'])\n",
    "            model_dict = model.state_dict()\n",
    "            # 1. filter out unnecessary keys\n",
    "            pretrained_dict = {k: v for k, v in pretrained_dict.items() if\n",
    "                               k in model_dict and v.shape == model_dict[k].shape}\n",
    "            # 2. overwrite entries in the existing state dict\n",
    "            model_dict.update(pretrained_dict)\n",
    "            # 3. load the new state dict\n",
    "            model.load_state_dict(model_dict)\n",
    "\n",
    "        elif pretrained_model == \"MPPN_GAF\":\n",
    "            print(\"Load pretrained MPPN trained with GAFs on variant classification\")\n",
    "            checkpoint = load_checkpoint(os.path.join(root_dir(), \"data\", \"ML\", \"checkpoint\"),\n",
    "                                         filename=\"MPPN_gaf_pretrained\")\n",
    "            best_model = checkpoint[\"model\"]\n",
    "            best_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "            model.CNN = best_model.CNN\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def mppn_representation_learning_model(pretrained, num_perspectives, output_attr, feature_size=64, representation_dim=128):\n",
    "    \"\"\"Returns a model for representation learning (multitask). CNN is pretrained on GAF images\"\"\"\n",
    "    model = MPPNMultitask(num_perspectives, output_attr, feature_size, representation_dim)\n",
    "\n",
    "    if pretrained:\n",
    "        print(\"Load pretrained MPPN trained with GAFs on variant classification\")\n",
    "        #checkpoint = load previously trained model on GAF images\n",
    "        best_model = checkpoint[\"model\"]\n",
    "        best_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "        model.CNN = best_model.CNN\n",
    "    else:\n",
    "        alexnet_mppn = mppn_pretraining_model(pretrained=True, num_perspectives=num_perspectives, num_classes=1)\n",
    "        model.CNN = alexnet_mppn.CNN\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def mppn_fine_tuning_model(representation_model, num_perspectives, num_classes):\n",
    "    \"\"\"\n",
    "    Fine-tune a MPPN model that has been trained as representation model on a specific task\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: Specifies the dataset, for which the model was trained before.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    model = MPPNClassifier(num_perspectives, num_classes=num_classes)\n",
    "\n",
    "    model.CNN = representation_model.CNN\n",
    "    model.MLP = representation_model.MLP\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "from PIL import Image\n",
    "\n",
    "def _gaf_loop(e,transformer):\n",
    "        inp,y=e\n",
    "        inp[inp>1]=1\n",
    "        inp[inp<0]=0\n",
    "        inp=inp*2-1\n",
    "        x=torch.stack(\n",
    "            tuple(_gaf_attr(inp[:,i],transformer) for i in range(inp.shape[1]))\n",
    "        ).transpose(0,1)\n",
    "        x=x[:,:,None].expand(-1,-1,3,-1,-1)\n",
    "        return x,y\n",
    "\n",
    "def _gaf_attr(x,transformer):\n",
    "    try:\n",
    "\n",
    "        x = transformer.transform(x)\n",
    "    except ValueError as e:\n",
    "        print(x)\n",
    "        raise e\n",
    "    x=tensor(x).cuda()\n",
    "    x = x * 255\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class gaf_transform(ItemTransform):\n",
    "    ''' GAF transormation: converts a bash into a gramian angular field and reshapes it to RGB'''\n",
    "    def __init__(self,gs=64):\n",
    "        self.transformer=GramianAngularField(image_size=gs,sample_range=None, method=\"s\", overlapping=True)\n",
    "\n",
    "    def encodes(self,e): return _gaf_loop(e,self.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=torch.rand((2556,10,100)),10\n",
    "gt=gaf_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.41 s, sys: 1.15 s, total: 6.57 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x,y=gt(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mppn_get_output_attributes(o):\n",
    "    '''Utility function that puts vocab size of each output attribute in a dict. \n",
    "    For regression tasks, it adds vocab size 1'''\n",
    "    output_attributes = {i:len(o.procs.categorify[i]) for i in o.ycat_names }\n",
    "    for i in o.ycont_names: output_attributes[i]=1\n",
    "    return output_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few cells show how to create a dataloader for MPPN and apply them to the representation learning and the finetuning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alexnet to train MPPNs CNN from scratch\n"
     ]
    }
   ],
   "source": [
    "# Create mppn repreentation learning and create the dataloader\n",
    "path=EventLogs.Mobis\n",
    "log=import_log(path)\n",
    "_t=attr_dict[get_ds_name(path)]\n",
    "cat_names,cont_names,date_names=[_t[i] for i in list(_t)]\n",
    "o=PPObj(log,[Categorify,Datetify,FillMissing,MinMax],\n",
    "        cat_names=cat_names,cont_names=cont_names,date_names=date_names,\n",
    "        splits=split_traces(log),y_names=['activity','resource','timestamp_Relative_elapsed_minmax'])\n",
    "output_attributes=mppn_get_output_attributes(o)\n",
    "m = mppn_representation_learning_model(False, len(o.cont_names), output_attributes)\n",
    "dls=o.get_dls(after_batch=gaf_transform,bs=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch\n",
    "xb,yb=dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss and metrics\n",
    "loss=partial(multi_loss_sum,o)\n",
    "metrics=get_metrics(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(11.4477, grad_fn=<AliasBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test forward pass\n",
    "xb=xb.cpu()\n",
    "p=m(xb)\n",
    "loss(p,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train representation learning model\n",
    "if _RUN_TRAINING:\n",
    "    train_validate(dls,m,loss=loss,metrics=metrics,epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fine-tuning model\n",
    "col='activity'\n",
    "m2 = mppn_fine_tuning_model(m, len(output_attributes), output_attributes[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change input and output features for the dataloader\n",
    "o.ycat_names=L(col)\n",
    "o.ycont_names=L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new dataloader for next-activity prediction\n",
    "dls=o.get_dls(after_batch=gaf_transform,bs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new loss and metrics for for next-activity prediction\n",
    "loss=partial(multi_loss_sum,o)\n",
    "metrics=get_metrics(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.0333, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test forward pass\n",
    "\n",
    "xb,yb=dls.one_batch()\n",
    "yb.shape\n",
    "\n",
    "p=m2.cuda()(xb.cuda())\n",
    "\n",
    "accuracy(p.cuda(),yb.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "if _RUN_TRAINING:\n",
    "    train_validate(dls,m2,loss=loss,metrics=metrics,epoch=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the PPM for the MPPM. In the setup der general representation learning model is trained. Afterwards, in each prediction task, a seperate head is created, which is than fine-tuned for the specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class PPM_MPPN(PPModel):\n",
    "\n",
    "\n",
    "    def _attr_from_dict(self,ds_name):\n",
    "        if not self.attr_dict: raise AttributeError('attr_dict is required!')\n",
    "\n",
    "        return (listify(self.attr_dict[self.ds_name]['cat attr']),\n",
    "                listify(self.attr_dict[self.ds_name]['num attr']),\n",
    "                listify(self.attr_dict[self.ds_name]['date attr']))\n",
    "\n",
    "\n",
    "    def setup(self):\n",
    "        def act_acc(p,y): return accuracy(p[0],y[0])\n",
    "        def act_res(p,y): return accuracy(p[1],y[1])\n",
    "        cat_names,cont_names,date_names=self._attr_from_dict(self.ds_name)\n",
    "        self.o=PPObj(self.log,[Categorify,Datetify,FillMissing,MinMax],\n",
    "                     cat_names=cat_names,date_names=date_names,cont_names=cont_names,\n",
    "                     y_names=['activity','resource','timestamp_Relative_elapsed'],\n",
    "                     splits=self.splits)\n",
    "        self.o.cont_names=['timestamp_Relative_elapsed']\n",
    "        norm=Normalize()\n",
    "        self.o.procs.add(norm,self.o)\n",
    "        self.mean=norm.means['timestamp_Relative_elapsed']\n",
    "        self.std=norm.stds['timestamp_Relative_elapsed']\n",
    "        self.o.cont_names=L(['activity_minmax','resource_minmax','timestamp_Relative_elapsed_minmax'])\n",
    "        self.output_attributes=mppn_get_output_attributes(self.o)\n",
    "        self.pretrain = mppn_representation_learning_model(False, len(self.o.cont_names), self.output_attributes)\n",
    "        dls=self.o.get_dls(after_batch=gaf_transform,bs=self.bs)\n",
    "        loss=partial(multi_loss_sum,self.o)\n",
    "        time_metric=lambda p,y: maeDurDaysNormalize(listify(p)[-1],listify(y)[-1],mean=self.mean,std=self.std)\n",
    "        self._train_validate(dls,self.pretrain,loss=loss,metrics=[act_acc,act_res,time_metric])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def next_step_prediction(self,col='activity',outcome=False):\n",
    "        pretrain=copy.deepcopy(self.pretrain)\n",
    "        m = mppn_fine_tuning_model(pretrain, len(self.output_attributes), self.output_attributes[col])\n",
    "        self.o.ycat_names,self.o.ycont_names=L(col),L()\n",
    "        dls=self.o.get_dls(after_batch=gaf_transform,bs=self.bs,outcome=outcome)\n",
    "        loss=partial(multi_loss_sum,self.o)\n",
    "        metrics=get_metrics(self.o)\n",
    "        return self._train_validate(dls,m,loss=loss,metrics=metrics)\n",
    "\n",
    "    def next_resource_prediction(self):return self.next_step_prediction(outcome=False,col='resource')\n",
    "\n",
    "    def last_resource_prediction(self): return self.next_step_prediction(outcome=True,col='resource')\n",
    "    def outcome_prediction(self): return self.next_step_prediction(outcome=True)\n",
    "\n",
    "    def duration_to_next_event_prediction(self,outcome=False,col='timestamp_Relative_elapsed'):\n",
    "        pretrain=copy.deepcopy(self.pretrain)\n",
    "        time=partial(maeDurDaysNormalize,mean=self.mean,std=self.std)\n",
    "        m = mppn_fine_tuning_model(pretrain, len(self.output_attributes), self.output_attributes[col])\n",
    "        self.o.ycat_names,self.o.ycont_names=L(),L(col)\n",
    "        dls=self.o.get_dls(after_batch=gaf_transform,bs=self.bs,outcome=outcome)\n",
    "        xb,yb=dls.one_batch()\n",
    "        return self._train_validate(dls,m,loss=mae,metrics=time)\n",
    "\n",
    "\n",
    "    def duration_to_end_prediction(self):return self.duration_to_next_event_prediction(outcome=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if  _RUN_TRAINING:\n",
    "    path=EventLogs.BPIC_12_O\n",
    "    log=import_log(path)\n",
    "    ppm=PPM_MPPN(log,get_ds_name(path),split_traces(log),print_output=True,epoch=5,bs=512,attr_dict=attr_dict)\n",
    "    ppm.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _RUN_TRAINING: ppm.next_step_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _RUN_TRAINING: ppm.duration_to_next_event_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _RUN_TRAINING: ppm.duration_to_end_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mppn",
   "language": "python",
   "name": "mppn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
